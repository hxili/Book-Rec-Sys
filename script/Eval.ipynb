{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1917278-756a-4e15-82e3-fd0e89208e5d",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-02T11:58:47.651847Z",
     "iopub.status.busy": "2024-01-02T11:58:47.651356Z",
     "iopub.status.idle": "2024-01-02T11:58:48.786876Z",
     "shell.execute_reply": "2024-01-02T11:58:48.786058Z",
     "shell.execute_reply.started": "2024-01-02T11:58:47.651817Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Data Loaded\n",
      "   user_id  book_id  rating\n",
      "0        1      258       5\n",
      "1        2     4081       4\n",
      "2        2      260       5\n",
      "3        2     9296       5\n",
      "4        2     2318       3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.sparse import coo_matrix\n",
    "import os\n",
    "\n",
    "\n",
    "input_dir = '/mnt/workspace/Book-Rec-Sys/input'\n",
    "\n",
    "def load_data():\n",
    "    ratings = pd.read_csv(f'{input_dir}/train_data.csv')\n",
    "    print(\"Ratings Data Loaded\")\n",
    "    print(ratings.head())\n",
    "    return ratings\n",
    "\n",
    "ratings = load_data()\n",
    "\n",
    "num_users = ratings['user_id'].max()\n",
    "num_books = ratings['book_id'].max()\n",
    "\n",
    "# Convert to a sparse matrix\n",
    "rows = ratings['user_id'] - 1\n",
    "cols = ratings['book_id'] - 1\n",
    "values = ratings['rating']\n",
    "rating_matrix = coo_matrix((values, (rows, cols)), shape=(num_users, num_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "341a6b74-3741-49bd-8702-8b299c49a900",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-02T11:59:28.864064Z",
     "iopub.status.busy": "2024-01-02T11:59:28.863594Z",
     "iopub.status.idle": "2024-01-02T11:59:28.874779Z",
     "shell.execute_reply": "2024-01-02T11:59:28.874063Z",
     "shell.execute_reply.started": "2024-01-02T11:59:28.864034Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrices on step 0 loaded successfully.\n",
      "Matrices on step 125 loaded successfully.\n",
      "Matrices on step 250 loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "def load_matrices(step, output_dir):\n",
    "    P_path = os.path.join(output_dir, f'P_step_{step}.pt')\n",
    "    Q_path = os.path.join(output_dir, f'Q_step_{step}.pt')\n",
    "\n",
    "    if os.path.exists(P_path) and os.path.exists(Q_path):\n",
    "        P = torch.load(P_path)\n",
    "        Q = torch.load(Q_path)\n",
    "        return P, Q.T\n",
    "    else:\n",
    "        print(f\"Files for step {step} not found.\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "output_dir = '/mnt/workspace/Book-Rec-Sys/output'  # Update with your directory path\n",
    "steps = range(0, 251, 125) \n",
    "\n",
    "for step in steps:\n",
    "    P, Q = load_matrices(step, output_dir)\n",
    "    if P is not None and Q is not None:\n",
    "        print(f\"Matrices on step {step} loaded successfully.\")\n",
    "        # You can now use P and Q for further computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "676c477c-c9f0-4f2f-b44a-f20de30564d0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-02T11:59:36.135843Z",
     "iopub.status.busy": "2024-01-02T11:59:36.135374Z",
     "iopub.status.idle": "2024-01-02T11:59:46.096167Z",
     "shell.execute_reply": "2024-01-02T11:59:46.095415Z",
     "shell.execute_reply.started": "2024-01-02T11:59:36.135811Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrices on step 0 loaded successfully.\n",
      "Prediction Error: 3.0257887840270996\n",
      "Matrices on step 125 loaded successfully.\n",
      "Prediction Error: 1.0780941247940063\n",
      "Matrices on step 250 loaded successfully.\n",
      "Prediction Error: 0.9327813982963562\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for step in steps:\n",
    "    P, Q = load_matrices(step, output_dir)\n",
    "    if P is not None and Q is not None:\n",
    "        print(f\"Matrices on step {step} loaded successfully.\")\n",
    "        # You can now use P and Q for further computations\n",
    "\n",
    "    predicted_ratings = torch.matmul(P, Q.T)\n",
    "    actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "    mask = actual_ratings > 0\n",
    "\n",
    "    # Ensure both tensors are on the same device before subtraction\n",
    "    error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "\n",
    "    print(\"Prediction Error:\", error.item())  # Convert to Python scalar for printing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
