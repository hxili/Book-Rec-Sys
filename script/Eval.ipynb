{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1917278-756a-4e15-82e3-fd0e89208e5d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-02T01:40:43.405847Z",
     "iopub.status.busy": "2024-01-02T01:40:43.405133Z",
     "iopub.status.idle": "2024-01-02T01:40:45.423766Z",
     "shell.execute_reply": "2024-01-02T01:40:45.422978Z",
     "shell.execute_reply.started": "2024-01-02T01:40:43.405815Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Data Loaded\n",
      "   user_id  book_id  rating\n",
      "0        1      258       5\n",
      "1        2     4081       4\n",
      "2        2      260       5\n",
      "3        2     9296       5\n",
      "4        2     2318       3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.sparse import coo_matrix\n",
    "import os\n",
    "\n",
    "\n",
    "input_dir = '/mnt/workspace/Book-Rec-Sys/input/dataset'\n",
    "\n",
    "def load_data():\n",
    "    ratings = pd.read_csv(f'{input_dir}/ratings.csv')\n",
    "    print(\"Ratings Data Loaded\")\n",
    "    print(ratings.head())\n",
    "    return ratings\n",
    "\n",
    "ratings = load_data()\n",
    "\n",
    "num_users = ratings['user_id'].max()\n",
    "num_books = ratings['book_id'].max()\n",
    "\n",
    "# Convert to a sparse matrix\n",
    "rows = ratings['user_id'] - 1\n",
    "cols = ratings['book_id'] - 1\n",
    "values = ratings['rating']\n",
    "rating_matrix = coo_matrix((values, (rows, cols)), shape=(num_users, num_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "341a6b74-3741-49bd-8702-8b299c49a900",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-02T01:37:51.968254Z",
     "iopub.status.busy": "2024-01-02T01:37:51.967496Z",
     "iopub.status.idle": "2024-01-02T01:37:51.986815Z",
     "shell.execute_reply": "2024-01-02T01:37:51.985947Z",
     "shell.execute_reply.started": "2024-01-02T01:37:51.968222Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrices on step 0 loaded successfully.\n",
      "Matrices on step 250 loaded successfully.\n",
      "Matrices on step 500 loaded successfully.\n",
      "Matrices on step 750 loaded successfully.\n",
      "Matrices on step 1000 loaded successfully.\n",
      "Matrices on step 1250 loaded successfully.\n",
      "Matrices on step 1500 loaded successfully.\n",
      "Matrices on step 1750 loaded successfully.\n",
      "Matrices on step 2000 loaded successfully.\n",
      "Matrices on step 2250 loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "def load_matrices(step, output_dir):\n",
    "    P_path = os.path.join(output_dir, f'P_step_{step}.pt')\n",
    "    Q_path = os.path.join(output_dir, f'Q_step_{step}.pt')\n",
    "\n",
    "    if os.path.exists(P_path) and os.path.exists(Q_path):\n",
    "        P = torch.load(P_path)\n",
    "        Q = torch.load(Q_path)\n",
    "        return P, Q.T\n",
    "    else:\n",
    "        print(f\"Files for step {step} not found.\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "output_dir = '/mnt/workspace/Book-Rec-Sys/output'  # Update with your directory path\n",
    "steps = range(0, 2251, 250) \n",
    "\n",
    "for step in steps:\n",
    "    P, Q = load_matrices(step, output_dir)\n",
    "    if P is not None and Q is not None:\n",
    "        print(f\"Matrices on step {step} loaded successfully.\")\n",
    "        # You can now use P and Q for further computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "676c477c-c9f0-4f2f-b44a-f20de30564d0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-02T01:41:34.015918Z",
     "iopub.status.busy": "2024-01-02T01:41:34.015202Z",
     "iopub.status.idle": "2024-01-02T01:42:07.578360Z",
     "shell.execute_reply": "2024-01-02T01:42:07.577478Z",
     "shell.execute_reply.started": "2024-01-02T01:41:34.015872Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrices on step 0 loaded successfully.\n",
      "Prediction Error: 3.0257887840270996\n",
      "Matrices on step 250 loaded successfully.\n",
      "Prediction Error: 0.9021819233894348\n",
      "Matrices on step 500 loaded successfully.\n",
      "Prediction Error: 0.836444079875946\n",
      "Matrices on step 750 loaded successfully.\n",
      "Prediction Error: 0.8191856741905212\n",
      "Matrices on step 1000 loaded successfully.\n",
      "Prediction Error: 0.8147655129432678\n",
      "Matrices on step 1250 loaded successfully.\n",
      "Prediction Error: 0.8132274150848389\n",
      "Matrices on step 1500 loaded successfully.\n",
      "Prediction Error: 0.8125643134117126\n",
      "Matrices on step 1750 loaded successfully.\n",
      "Prediction Error: 0.8122180700302124\n",
      "Matrices on step 2000 loaded successfully.\n",
      "Prediction Error: 0.8119957447052002\n",
      "Matrices on step 2250 loaded successfully.\n",
      "Prediction Error: 0.8118148446083069\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for step in steps:\n",
    "    P, Q = load_matrices(step, output_dir)\n",
    "    if P is not None and Q is not None:\n",
    "        print(f\"Matrices on step {step} loaded successfully.\")\n",
    "        # You can now use P and Q for further computations\n",
    "\n",
    "    predicted_ratings = torch.matmul(P, Q.T)\n",
    "    actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "    mask = actual_ratings > 0\n",
    "\n",
    "    # Ensure both tensors are on the same device before subtraction\n",
    "    error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "\n",
    "    print(\"Prediction Error:\", error.item())  # Convert to Python scalar for printing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
