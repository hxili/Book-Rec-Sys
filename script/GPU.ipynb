{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbfaa8ee-7a47-42fa-9162-f330eb98c672",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T10:52:46.023876Z",
     "iopub.status.busy": "2024-01-03T10:52:46.023060Z",
     "iopub.status.idle": "2024-01-03T10:52:48.067497Z",
     "shell.execute_reply": "2024-01-03T10:52:48.066944Z",
     "shell.execute_reply.started": "2024-01-03T10:52:46.023854Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Data Loaded\n",
      "   user_id  book_id  rating\n",
      "0    10714     7164       3\n",
      "1    48091     2213       3\n",
      "2     9809     5769       4\n",
      "3    25191       86       5\n",
      "4    25441     4884       3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.sparse import coo_matrix\n",
    "import os\n",
    "\n",
    "d = '/mnt/workspace/Book-Rec-Sys/input'\n",
    "o = '/mnt/workspace/Book-Rec-Sys/output'\n",
    "\n",
    "def load_data():\n",
    "    ratings = pd.read_csv(f'{d}/train_data.csv')\n",
    "    print(\"Ratings Data Loaded\")\n",
    "    print(ratings.head())\n",
    "    return ratings\n",
    "\n",
    "ratings = load_data()\n",
    "\n",
    "num_users = ratings['user_id'].max()\n",
    "num_books = ratings['book_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc97b93-c5fb-4e00-8ad9-0523393e5f97",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T10:52:48.068457Z",
     "iopub.status.busy": "2024-01-03T10:52:48.068263Z",
     "iopub.status.idle": "2024-01-03T10:52:48.114012Z",
     "shell.execute_reply": "2024-01-03T10:52:48.113448Z",
     "shell.execute_reply.started": "2024-01-03T10:52:48.068438Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to a sparse matrix\n",
    "rows = ratings['user_id'] - 1\n",
    "cols = ratings['book_id'] - 1\n",
    "values = ratings['rating']\n",
    "rating_matrix = coo_matrix((values, (rows, cols)), shape=(num_users, num_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3a854c-f541-4bc7-8ac6-a83a32aed11c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T10:52:48.115289Z",
     "iopub.status.busy": "2024-01-03T10:52:48.114813Z",
     "iopub.status.idle": "2024-01-03T10:52:48.123063Z",
     "shell.execute_reply": "2024-01-03T10:52:48.122573Z",
     "shell.execute_reply.started": "2024-01-03T10:52:48.115263Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matrix_factorization(R, K, steps=5000, alpha=0.0001, beta=0, save_interval=1, output_dir='output', device='cuda'):\n",
    "    R = torch.FloatTensor(R.toarray()).to(device)\n",
    "    num_users, num_books = R.shape\n",
    "    P = torch.rand(num_users, K, device=device)\n",
    "    Q = torch.rand(num_books, K, device=device).T\n",
    "\n",
    "    for step in range(steps):\n",
    "        for i in range(num_users):\n",
    "            rated_indices = R[i, :].nonzero().view(-1)\n",
    "            Q_i = Q[:, rated_indices]\n",
    "            R_i = R[i, rated_indices]\n",
    "            e_i = R_i - torch.matmul(P[i, :], Q_i)\n",
    "            P[i, :] += alpha * (torch.matmul(e_i, Q_i.T) - beta * P[i, :])\n",
    "\n",
    "        for j in range(num_books):\n",
    "            rated_indices = R[:, j].nonzero().view(-1)\n",
    "            P_j = P[rated_indices, :]\n",
    "            R_j = R[rated_indices, j]\n",
    "            e_j = R_j - torch.matmul(P_j, Q[:, j])\n",
    "            Q[:, j] += alpha * (torch.matmul(P_j.T, e_j) - beta * Q[:, j])\n",
    "\n",
    "        eR = torch.matmul(P, Q)\n",
    "        e = torch.sum((R[R > 0] - eR[R > 0]) ** 2)\n",
    "        e += beta / 2 * (torch.sum(P ** 2) + torch.sum(Q ** 2))\n",
    "        \n",
    "        # Save P and Q every 'save_interval' steps, print loss function calculate the prediction error\n",
    "        if step % save_interval == 0 or step == steps - 1:\n",
    "#            torch.save(P, os.path.join(output_dir, f'P_step_{step}_alpha_{alpha}_beta_{beta}.pt'))\n",
    "#            torch.save(Q, os.path.join(output_dir, f'Q_step_{step}_alpha_{alpha}_beta_{beta}.pt'))\n",
    "            print(f'Saved P and Q at step {step}')\n",
    "            print(\"loss:\", e.item())\n",
    "            predicted_ratings = torch.matmul(P, Q)\n",
    "            actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "            mask = actual_ratings > 0\n",
    "            # Ensure both tensors are on the same device before subtraction\n",
    "            error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "            print(\"Prediction Error:\", error.item())  # Convert to Python scalar for printing\n",
    "\n",
    "        if e < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d65856a3-28a2-4424-96ce-6f8182c8c4ea",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T10:52:48.124856Z",
     "iopub.status.busy": "2024-01-03T10:52:48.124506Z",
     "iopub.status.idle": "2024-01-03T10:52:48.132538Z",
     "shell.execute_reply": "2024-01-03T10:52:48.132076Z",
     "shell.execute_reply.started": "2024-01-03T10:52:48.124836Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matrix_factorization_continue(R, K, end_step, steps=5000, alpha=0.0000001, beta=0.01, save_interval=125, output_dir='output', device='cuda'):\n",
    "    R = torch.FloatTensor(R.toarray()).to(device)\n",
    "    num_users, num_books = R.shape\n",
    "    # Attempt to load P and Q from saved files\n",
    "    P_path = os.path.join(output_dir, f'P_step_{end_step}.pt')\n",
    "    Q_path = os.path.join(output_dir, f'Q_step_{end_step}.pt')\n",
    "    P = torch.load(P_path, map_location=device)\n",
    "    Q = torch.load(Q_path, map_location=device)\n",
    "    print(f\"Continuing from step {end_step}...\")\n",
    "\n",
    "\n",
    "    for step in range(end_step+1, steps):\n",
    "        # Matrix factorization steps...\n",
    "        # Existing matrix factorization logic in matrix_factorization\n",
    "        for i in range(num_users):\n",
    "            rated_indices = R[i, :].nonzero().view(-1)\n",
    "            Q_i = Q[:, rated_indices]\n",
    "            R_i = R[i, rated_indices]\n",
    "            e_i = R_i - torch.matmul(P[i, :], Q_i)\n",
    "            P[i, :] += alpha * (torch.matmul(e_i, Q_i.T) - beta * P[i, :])\n",
    "\n",
    "        for j in range(num_books):\n",
    "            rated_indices = R[:, j].nonzero().view(-1)\n",
    "            P_j = P[rated_indices, :]\n",
    "            R_j = R[rated_indices, j]\n",
    "            e_j = R_j - torch.matmul(P_j, Q[:, j])\n",
    "            Q[:, j] += alpha * (torch.matmul(P_j.T, e_j) - beta * Q[:, j])\n",
    "\n",
    "        eR = torch.matmul(P, Q)\n",
    "        e = torch.sum((R[R > 0] - eR[R > 0]) ** 2)\n",
    "        e += beta / 2 * (torch.sum(P ** 2) + torch.sum(Q ** 2))\n",
    "        \n",
    "        \n",
    "        # Save P and Q every 'save_interval' steps\n",
    "        if step % save_interval == 0 or step == steps - 1:\n",
    "            torch.save(P, os.path.join(output_dir, f'P_step_{step}.pt'))\n",
    "            torch.save(Q, os.path.join(output_dir, f'Q_step_{step}.pt'))\n",
    "            print(f'Saved P and Q at step {step}')\n",
    "\n",
    "        if e < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd17e94-3e32-4ae8-b71a-532f56f03e5e",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T10:52:48.133527Z",
     "iopub.status.busy": "2024-01-03T10:52:48.133215Z",
     "iopub.status.idle": "2024-01-03T10:52:48.137111Z",
     "shell.execute_reply": "2024-01-03T10:52:48.136603Z",
     "shell.execute_reply.started": "2024-01-03T10:52:48.133508Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init(K):\n",
    "    # Run the matrix factorization\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    P, Q = matrix_factorization(rating_matrix, K, device=device, output_dir=o)\n",
    "\n",
    "\n",
    "    predicted_ratings = torch.matmul(P, Q.T)\n",
    "    actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "    mask = actual_ratings > 0\n",
    "\n",
    "    # Ensure both tensors are on the same device before subtraction\n",
    "    error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "\n",
    "    print(\"Prediction Error:\", error.item())  # Convert to Python scalar for printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c785f1-7e14-42f5-8680-ddf0d1623339",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T10:52:48.138107Z",
     "iopub.status.busy": "2024-01-03T10:52:48.137933Z",
     "iopub.status.idle": "2024-01-03T10:52:48.141578Z",
     "shell.execute_reply": "2024-01-03T10:52:48.141036Z",
     "shell.execute_reply.started": "2024-01-03T10:52:48.138089Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cont(end_step):\n",
    "    K = 2  # Example value\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    P, Q = matrix_factorization_continue(rating_matrix, K, end_step, device=device, output_dir=o)\n",
    "\n",
    "    predicted_ratings = torch.matmul(P, Q.T)\n",
    "    actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "    mask = actual_ratings > 0\n",
    "\n",
    "    # Ensure both tensors are on the same device before subtraction\n",
    "    error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "247b02e1-6c02-4441-8fff-c6ecf0167565",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T10:52:48.142456Z",
     "iopub.status.busy": "2024-01-03T10:52:48.142293Z",
     "iopub.status.idle": "2024-01-03T10:52:48.144741Z",
     "shell.execute_reply": "2024-01-03T10:52:48.144215Z",
     "shell.execute_reply.started": "2024-01-03T10:52:48.142438Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Empty cuda memory\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6282ea-c55b-437d-8a28-796b714a158b",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T10:52:48.145694Z",
     "iopub.status.busy": "2024-01-03T10:52:48.145515Z",
     "iopub.status.idle": "2024-01-03T10:52:48.147814Z",
     "shell.execute_reply": "2024-01-03T10:52:48.147294Z",
     "shell.execute_reply.started": "2024-01-03T10:52:48.145676Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init(15)\n",
    "#cont(1125)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
