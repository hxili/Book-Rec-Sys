{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbfaa8ee-7a47-42fa-9162-f330eb98c672",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-02T17:07:59.358702Z",
     "iopub.status.busy": "2024-01-02T17:07:59.358526Z",
     "iopub.status.idle": "2024-01-02T17:08:01.346722Z",
     "shell.execute_reply": "2024-01-02T17:08:01.346134Z",
     "shell.execute_reply.started": "2024-01-02T17:07:59.358682Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Data Loaded\n",
      "   user_id  book_id  rating\n",
      "0    10714     7164       3\n",
      "1    48091     2213       3\n",
      "2     9809     5769       4\n",
      "3    25191       86       5\n",
      "4    25441     4884       3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.sparse import coo_matrix\n",
    "import os\n",
    "\n",
    "d = '/mnt/workspace/Book-Rec-Sys/input'\n",
    "o = '/mnt/workspace/Book-Rec-Sys/output'\n",
    "\n",
    "def load_data():\n",
    "    ratings = pd.read_csv(f'{d}/train_data.csv')\n",
    "    print(\"Ratings Data Loaded\")\n",
    "    print(ratings.head())\n",
    "    return ratings\n",
    "\n",
    "ratings = load_data()\n",
    "\n",
    "num_users = ratings['user_id'].max()\n",
    "num_books = ratings['book_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc97b93-c5fb-4e00-8ad9-0523393e5f97",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-02T17:08:01.348394Z",
     "iopub.status.busy": "2024-01-02T17:08:01.347863Z",
     "iopub.status.idle": "2024-01-02T17:08:01.392868Z",
     "shell.execute_reply": "2024-01-02T17:08:01.392256Z",
     "shell.execute_reply.started": "2024-01-02T17:08:01.348370Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to a sparse matrix\n",
    "rows = ratings['user_id'] - 1\n",
    "cols = ratings['book_id'] - 1\n",
    "values = ratings['rating']\n",
    "rating_matrix = coo_matrix((values, (rows, cols)), shape=(num_users, num_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3a854c-f541-4bc7-8ac6-a83a32aed11c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-02T17:08:01.394203Z",
     "iopub.status.busy": "2024-01-02T17:08:01.393641Z",
     "iopub.status.idle": "2024-01-02T17:08:01.401329Z",
     "shell.execute_reply": "2024-01-02T17:08:01.400787Z",
     "shell.execute_reply.started": "2024-01-02T17:08:01.394176Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matrix_factorization(R, K, steps=5000, alpha=0.0003, beta=0.01, save_interval=125, output_dir='output', device='cuda'):\n",
    "    R = torch.FloatTensor(R.toarray()).to(device)\n",
    "    num_users, num_books = R.shape\n",
    "    P = torch.rand(num_users, K, device=device)\n",
    "    Q = torch.rand(num_books, K, device=device).T\n",
    "\n",
    "    for step in range(steps):\n",
    "        for i in range(num_users):\n",
    "            rated_indices = R[i, :].nonzero().view(-1)\n",
    "            Q_i = Q[:, rated_indices]\n",
    "            R_i = R[i, rated_indices]\n",
    "            e_i = R_i - torch.matmul(P[i, :], Q_i)\n",
    "            P[i, :] += alpha * (torch.matmul(e_i, Q_i.T) - beta * P[i, :])\n",
    "\n",
    "        for j in range(num_books):\n",
    "            rated_indices = R[:, j].nonzero().view(-1)\n",
    "            P_j = P[rated_indices, :]\n",
    "            R_j = R[rated_indices, j]\n",
    "            e_j = R_j - torch.matmul(P_j, Q[:, j])\n",
    "            Q[:, j] += alpha * (torch.matmul(P_j.T, e_j) - beta * Q[:, j])\n",
    "\n",
    "        eR = torch.matmul(P, Q)\n",
    "        e = torch.sum((R[R > 0] - eR[R > 0]) ** 2)\n",
    "        e += beta / 2 * (torch.sum(P ** 2) + torch.sum(Q ** 2))\n",
    "        \n",
    "        # Save P and Q every 'save_interval' steps\n",
    "        if step % save_interval == 0 or step == steps - 1:\n",
    "            torch.save(P, os.path.join(output_dir, f'P_step_{step}.pt'))\n",
    "            torch.save(Q, os.path.join(output_dir, f'Q_step_{step}.pt'))\n",
    "            print(f'Saved P and Q at step {step}')\n",
    "\n",
    "        if e < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d65856a3-28a2-4424-96ce-6f8182c8c4ea",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-02T17:08:01.403059Z",
     "iopub.status.busy": "2024-01-02T17:08:01.402711Z",
     "iopub.status.idle": "2024-01-02T17:08:01.410384Z",
     "shell.execute_reply": "2024-01-02T17:08:01.409819Z",
     "shell.execute_reply.started": "2024-01-02T17:08:01.403039Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matrix_factorization_continue(R, K, end_step, steps=5000, alpha=0.00001, beta=0.01, save_interval=125, output_dir='output', device='cuda'):\n",
    "    R = torch.FloatTensor(R.toarray()).to(device)\n",
    "    num_users, num_books = R.shape\n",
    "    # Attempt to load P and Q from saved files\n",
    "    P_path = os.path.join(output_dir, f'P_step_{end_step}.pt')\n",
    "    Q_path = os.path.join(output_dir, f'Q_step_{end_step}.pt')\n",
    "    P = torch.load(P_path, map_location=device)\n",
    "    Q = torch.load(Q_path, map_location=device)\n",
    "    print(f\"Continuing from step {end_step}...\")\n",
    "\n",
    "\n",
    "    for step in range(end_step+1, steps):\n",
    "        # Matrix factorization steps...\n",
    "        # Existing matrix factorization logic in matrix_factorization\n",
    "        for i in range(num_users):\n",
    "            rated_indices = R[i, :].nonzero().view(-1)\n",
    "            Q_i = Q[:, rated_indices]\n",
    "            R_i = R[i, rated_indices]\n",
    "            e_i = R_i - torch.matmul(P[i, :], Q_i)\n",
    "            P[i, :] += alpha * (torch.matmul(e_i, Q_i.T) - beta * P[i, :])\n",
    "\n",
    "        for j in range(num_books):\n",
    "            rated_indices = R[:, j].nonzero().view(-1)\n",
    "            P_j = P[rated_indices, :]\n",
    "            R_j = R[rated_indices, j]\n",
    "            e_j = R_j - torch.matmul(P_j, Q[:, j])\n",
    "            Q[:, j] += alpha * (torch.matmul(P_j.T, e_j) - beta * Q[:, j])\n",
    "\n",
    "        eR = torch.matmul(P, Q)\n",
    "        e = torch.sum((R[R > 0] - eR[R > 0]) ** 2)\n",
    "        e += beta / 2 * (torch.sum(P ** 2) + torch.sum(Q ** 2))\n",
    "        \n",
    "        \n",
    "        # Save P and Q every 'save_interval' steps\n",
    "        if step % save_interval == 0 or step == steps - 1:\n",
    "            torch.save(P, os.path.join(output_dir, f'P_step_{step}.pt'))\n",
    "            torch.save(Q, os.path.join(output_dir, f'Q_step_{step}.pt'))\n",
    "            print(f'Saved P and Q at step {step}')\n",
    "\n",
    "        if e < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd17e94-3e32-4ae8-b71a-532f56f03e5e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-02T17:08:01.411353Z",
     "iopub.status.busy": "2024-01-02T17:08:01.411017Z",
     "iopub.status.idle": "2024-01-02T17:08:01.415018Z",
     "shell.execute_reply": "2024-01-02T17:08:01.414451Z",
     "shell.execute_reply.started": "2024-01-02T17:08:01.411334Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init():\n",
    "    K = 2\n",
    "\n",
    "    # Run the matrix factorization\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    P, Q = matrix_factorization(rating_matrix, K, device=device, output_dir=o)\n",
    "\n",
    "\n",
    "    predicted_ratings = torch.matmul(P, Q.T)\n",
    "    actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "    mask = actual_ratings > 0\n",
    "\n",
    "    # Ensure both tensors are on the same device before subtraction\n",
    "    error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "\n",
    "    print(\"Prediction Error:\", error.item())  # Convert to Python scalar for printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c785f1-7e14-42f5-8680-ddf0d1623339",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-02T17:08:01.415997Z",
     "iopub.status.busy": "2024-01-02T17:08:01.415656Z",
     "iopub.status.idle": "2024-01-02T17:08:01.419561Z",
     "shell.execute_reply": "2024-01-02T17:08:01.418985Z",
     "shell.execute_reply.started": "2024-01-02T17:08:01.415978Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cont(end_step):\n",
    "    K = 2  # Example value\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    P, Q = matrix_factorization_continue(rating_matrix, K, end_step, device=device, output_dir=o)\n",
    "\n",
    "    predicted_ratings = torch.matmul(P, Q.T)\n",
    "    actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "    mask = actual_ratings > 0\n",
    "\n",
    "    # Ensure both tensors are on the same device before subtraction\n",
    "    error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6282ea-c55b-437d-8a28-796b714a158b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-02T17:08:30.437151Z",
     "iopub.status.busy": "2024-01-02T17:08:30.436544Z",
     "iopub.status.idle": "2024-01-02T17:08:48.224862Z",
     "shell.execute_reply": "2024-01-02T17:08:48.223959Z",
     "shell.execute_reply.started": "2024-01-02T17:08:30.437123Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing from step 750...\n",
      "Saved P and Q at step 751\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcont\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m750\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Empty cuda memory\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#torch.cuda.empty_cache()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m, in \u001b[0;36mcont\u001b[0;34m(end_step)\u001b[0m\n\u001b[1;32m      2\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Example value\u001b[39;00m\n\u001b[1;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m P, Q \u001b[38;5;241m=\u001b[39m \u001b[43mmatrix_factorization_continue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrating_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m predicted_ratings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(P, Q\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m      7\u001b[0m actual_ratings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(rating_matrix\u001b[38;5;241m.\u001b[39mtoarray())\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Convert to PyTorch tensor\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m, in \u001b[0;36mmatrix_factorization_continue\u001b[0;34m(R, K, end_step, steps, alpha, beta, save_interval, output_dir, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(end_step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, steps):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Matrix factorization steps...\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Existing matrix factorization logic in matrix_factorization\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_users):\n\u001b[0;32m---> 16\u001b[0m         rated_indices \u001b[38;5;241m=\u001b[39m \u001b[43mR\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m         Q_i \u001b[38;5;241m=\u001b[39m Q[:, rated_indices]\n\u001b[1;32m     18\u001b[0m         R_i \u001b[38;5;241m=\u001b[39m R[i, rated_indices]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cont(750)\n",
    "# Empty cuda memory\n",
    "#torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
