{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbfaa8ee-7a47-42fa-9162-f330eb98c672",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:16.503802Z",
     "iopub.status.busy": "2024-01-03T09:03:16.503621Z",
     "iopub.status.idle": "2024-01-03T09:03:18.641398Z",
     "shell.execute_reply": "2024-01-03T09:03:18.640810Z",
     "shell.execute_reply.started": "2024-01-03T09:03:16.503782Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Data Loaded\n",
      "   user_id  book_id  rating\n",
      "0    10714     7164       3\n",
      "1    48091     2213       3\n",
      "2     9809     5769       4\n",
      "3    25191       86       5\n",
      "4    25441     4884       3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.sparse import coo_matrix\n",
    "import os\n",
    "\n",
    "d = '/mnt/workspace/Book-Rec-Sys/input'\n",
    "o = '/mnt/workspace/Book-Rec-Sys/output'\n",
    "\n",
    "def load_data():\n",
    "    ratings = pd.read_csv(f'{d}/train_data.csv')\n",
    "    print(\"Ratings Data Loaded\")\n",
    "    print(ratings.head())\n",
    "    return ratings\n",
    "\n",
    "ratings = load_data()\n",
    "\n",
    "num_users = ratings['user_id'].max()\n",
    "num_books = ratings['book_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc97b93-c5fb-4e00-8ad9-0523393e5f97",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:18.642565Z",
     "iopub.status.busy": "2024-01-03T09:03:18.642209Z",
     "iopub.status.idle": "2024-01-03T09:03:18.692656Z",
     "shell.execute_reply": "2024-01-03T09:03:18.692089Z",
     "shell.execute_reply.started": "2024-01-03T09:03:18.642544Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to a sparse matrix\n",
    "rows = ratings['user_id'] - 1\n",
    "cols = ratings['book_id'] - 1\n",
    "values = ratings['rating']\n",
    "rating_matrix = coo_matrix((values, (rows, cols)), shape=(num_users, num_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3a854c-f541-4bc7-8ac6-a83a32aed11c",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:18.694597Z",
     "iopub.status.busy": "2024-01-03T09:03:18.694298Z",
     "iopub.status.idle": "2024-01-03T09:03:18.702705Z",
     "shell.execute_reply": "2024-01-03T09:03:18.702125Z",
     "shell.execute_reply.started": "2024-01-03T09:03:18.694576Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matrix_factorization(R, K, steps=5000, alpha=0.00005, beta=0.01, save_interval=5, output_dir='output', device='cuda'):\n",
    "    R = torch.FloatTensor(R.toarray()).to(device)\n",
    "    num_users, num_books = R.shape\n",
    "    P = torch.rand(num_users, K, device=device)\n",
    "    Q = torch.rand(num_books, K, device=device).T\n",
    "\n",
    "    for step in range(steps):\n",
    "        for i in range(num_users):\n",
    "            rated_indices = R[i, :].nonzero().view(-1)\n",
    "            Q_i = Q[:, rated_indices]\n",
    "            R_i = R[i, rated_indices]\n",
    "            e_i = R_i - torch.matmul(P[i, :], Q_i)\n",
    "            P[i, :] += alpha * (torch.matmul(e_i, Q_i.T) - beta * P[i, :])\n",
    "\n",
    "        for j in range(num_books):\n",
    "            rated_indices = R[:, j].nonzero().view(-1)\n",
    "            P_j = P[rated_indices, :]\n",
    "            R_j = R[rated_indices, j]\n",
    "            e_j = R_j - torch.matmul(P_j, Q[:, j])\n",
    "            Q[:, j] += alpha * (torch.matmul(P_j.T, e_j) - beta * Q[:, j])\n",
    "\n",
    "        eR = torch.matmul(P, Q)\n",
    "        e = torch.sum((R[R > 0] - eR[R > 0]) ** 2)\n",
    "        e += beta / 2 * (torch.sum(P ** 2) + torch.sum(Q ** 2))\n",
    "        \n",
    "        # Save P and Q every 'save_interval' steps, print loss function calculate the prediction error\n",
    "        if step % save_interval == 0 or step == steps - 1:\n",
    "#            torch.save(P, os.path.join(output_dir, f'P_step_{step}_alpha_{alpha}_beta_{beta}.pt'))\n",
    "#            torch.save(Q, os.path.join(output_dir, f'Q_step_{step}_alpha_{alpha}_beta_{beta}.pt'))\n",
    "            print(f'Saved P and Q at step {step}')\n",
    "            print(\"loss:\", e)\n",
    "            predicted_ratings = torch.matmul(P, Q)\n",
    "            actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "            mask = actual_ratings > 0\n",
    "            # Ensure both tensors are on the same device before subtraction\n",
    "            error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "            print(\"Prediction Error:\", error.item())  # Convert to Python scalar for printing\n",
    "\n",
    "        if e < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d65856a3-28a2-4424-96ce-6f8182c8c4ea",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:18.703807Z",
     "iopub.status.busy": "2024-01-03T09:03:18.703520Z",
     "iopub.status.idle": "2024-01-03T09:03:18.712054Z",
     "shell.execute_reply": "2024-01-03T09:03:18.711496Z",
     "shell.execute_reply.started": "2024-01-03T09:03:18.703779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matrix_factorization_continue(R, K, end_step, steps=5000, alpha=0.0000001, beta=0.01, save_interval=125, output_dir='output', device='cuda'):\n",
    "    R = torch.FloatTensor(R.toarray()).to(device)\n",
    "    num_users, num_books = R.shape\n",
    "    # Attempt to load P and Q from saved files\n",
    "    P_path = os.path.join(output_dir, f'P_step_{end_step}.pt')\n",
    "    Q_path = os.path.join(output_dir, f'Q_step_{end_step}.pt')\n",
    "    P = torch.load(P_path, map_location=device)\n",
    "    Q = torch.load(Q_path, map_location=device)\n",
    "    print(f\"Continuing from step {end_step}...\")\n",
    "\n",
    "\n",
    "    for step in range(end_step+1, steps):\n",
    "        # Matrix factorization steps...\n",
    "        # Existing matrix factorization logic in matrix_factorization\n",
    "        for i in range(num_users):\n",
    "            rated_indices = R[i, :].nonzero().view(-1)\n",
    "            Q_i = Q[:, rated_indices]\n",
    "            R_i = R[i, rated_indices]\n",
    "            e_i = R_i - torch.matmul(P[i, :], Q_i)\n",
    "            P[i, :] += alpha * (torch.matmul(e_i, Q_i.T) - beta * P[i, :])\n",
    "\n",
    "        for j in range(num_books):\n",
    "            rated_indices = R[:, j].nonzero().view(-1)\n",
    "            P_j = P[rated_indices, :]\n",
    "            R_j = R[rated_indices, j]\n",
    "            e_j = R_j - torch.matmul(P_j, Q[:, j])\n",
    "            Q[:, j] += alpha * (torch.matmul(P_j.T, e_j) - beta * Q[:, j])\n",
    "\n",
    "        eR = torch.matmul(P, Q)\n",
    "        e = torch.sum((R[R > 0] - eR[R > 0]) ** 2)\n",
    "        e += beta / 2 * (torch.sum(P ** 2) + torch.sum(Q ** 2))\n",
    "        \n",
    "        \n",
    "        # Save P and Q every 'save_interval' steps\n",
    "        if step % save_interval == 0 or step == steps - 1:\n",
    "            torch.save(P, os.path.join(output_dir, f'P_step_{step}.pt'))\n",
    "            torch.save(Q, os.path.join(output_dir, f'Q_step_{step}.pt'))\n",
    "            print(f'Saved P and Q at step {step}')\n",
    "\n",
    "        if e < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd17e94-3e32-4ae8-b71a-532f56f03e5e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:18.713108Z",
     "iopub.status.busy": "2024-01-03T09:03:18.712843Z",
     "iopub.status.idle": "2024-01-03T09:03:18.716988Z",
     "shell.execute_reply": "2024-01-03T09:03:18.716491Z",
     "shell.execute_reply.started": "2024-01-03T09:03:18.713089Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init():\n",
    "    K = 3\n",
    "\n",
    "    # Run the matrix factorization\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    P, Q = matrix_factorization(rating_matrix, K, device=device, output_dir=o)\n",
    "\n",
    "\n",
    "    predicted_ratings = torch.matmul(P, Q.T)\n",
    "    actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "    mask = actual_ratings > 0\n",
    "\n",
    "    # Ensure both tensors are on the same device before subtraction\n",
    "    error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "\n",
    "    print(\"Prediction Error:\", error.item())  # Convert to Python scalar for printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c785f1-7e14-42f5-8680-ddf0d1623339",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:18.717909Z",
     "iopub.status.busy": "2024-01-03T09:03:18.717711Z",
     "iopub.status.idle": "2024-01-03T09:03:18.721689Z",
     "shell.execute_reply": "2024-01-03T09:03:18.721129Z",
     "shell.execute_reply.started": "2024-01-03T09:03:18.717890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cont(end_step):\n",
    "    K = 2  # Example value\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    P, Q = matrix_factorization_continue(rating_matrix, K, end_step, device=device, output_dir=o)\n",
    "\n",
    "    predicted_ratings = torch.matmul(P, Q.T)\n",
    "    actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "    mask = actual_ratings > 0\n",
    "\n",
    "    # Ensure both tensors are on the same device before subtraction\n",
    "    error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "247b02e1-6c02-4441-8fff-c6ecf0167565",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:18.722535Z",
     "iopub.status.busy": "2024-01-03T09:03:18.722356Z",
     "iopub.status.idle": "2024-01-03T09:03:18.725133Z",
     "shell.execute_reply": "2024-01-03T09:03:18.724586Z",
     "shell.execute_reply.started": "2024-01-03T09:03:18.722515Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Empty cuda memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6282ea-c55b-437d-8a28-796b714a158b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:30.406177Z",
     "iopub.status.busy": "2024-01-03T09:03:30.405801Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved P and Q at step 0\n",
      "Prediction Error: 3.06084942817688\n",
      "Saved P and Q at step 1\n",
      "Prediction Error: 2.8878180980682373\n",
      "Saved P and Q at step 2\n",
      "Prediction Error: 2.756591558456421\n",
      "Saved P and Q at step 3\n",
      "Prediction Error: 2.6476857662200928\n",
      "Saved P and Q at step 4\n",
      "Prediction Error: 2.5528712272644043\n",
      "Saved P and Q at step 5\n",
      "Prediction Error: 2.468003749847412\n",
      "Saved P and Q at step 6\n",
      "Prediction Error: 2.3906948566436768\n",
      "Saved P and Q at step 7\n",
      "Prediction Error: 2.3194313049316406\n",
      "Saved P and Q at step 8\n",
      "Prediction Error: 2.2531867027282715\n",
      "Saved P and Q at step 9\n",
      "Prediction Error: 2.1912310123443604\n",
      "Saved P and Q at step 10\n",
      "Prediction Error: 2.133023977279663\n",
      "Saved P and Q at step 11\n",
      "Prediction Error: 2.0781524181365967\n",
      "Saved P and Q at step 12\n",
      "Prediction Error: 2.026289224624634\n",
      "Saved P and Q at step 13\n",
      "Prediction Error: 1.9771701097488403\n",
      "Saved P and Q at step 14\n",
      "Prediction Error: 1.9305744171142578\n",
      "Saved P and Q at step 15\n",
      "Prediction Error: 1.8863152265548706\n",
      "Saved P and Q at step 16\n",
      "Prediction Error: 1.844230055809021\n",
      "Saved P and Q at step 17\n",
      "Prediction Error: 1.8041765689849854\n",
      "Saved P and Q at step 18\n",
      "Prediction Error: 1.7660274505615234\n",
      "Saved P and Q at step 19\n",
      "Prediction Error: 1.729668378829956\n",
      "Saved P and Q at step 20\n",
      "Prediction Error: 1.6949952840805054\n",
      "Saved P and Q at step 21\n",
      "Prediction Error: 1.6619127988815308\n",
      "Saved P and Q at step 22\n",
      "Prediction Error: 1.6303330659866333\n",
      "Saved P and Q at step 23\n",
      "Prediction Error: 1.6001750230789185\n",
      "Saved P and Q at step 24\n",
      "Prediction Error: 1.5713632106781006\n",
      "Saved P and Q at step 25\n",
      "Prediction Error: 1.5438270568847656\n",
      "Saved P and Q at step 26\n",
      "Prediction Error: 1.517500877380371\n",
      "Saved P and Q at step 27\n",
      "Prediction Error: 1.4923232793807983\n",
      "Saved P and Q at step 28\n",
      "Prediction Error: 1.4682360887527466\n",
      "Saved P and Q at step 29\n",
      "Prediction Error: 1.4451849460601807\n",
      "Saved P and Q at step 30\n",
      "Prediction Error: 1.423119068145752\n",
      "Saved P and Q at step 31\n",
      "Prediction Error: 1.4019896984100342\n",
      "Saved P and Q at step 32\n",
      "Prediction Error: 1.3817517757415771\n",
      "Saved P and Q at step 33\n",
      "Prediction Error: 1.3623621463775635\n",
      "Saved P and Q at step 34\n",
      "Prediction Error: 1.3437801599502563\n",
      "Saved P and Q at step 35\n",
      "Prediction Error: 1.3259676694869995\n",
      "Saved P and Q at step 36\n",
      "Prediction Error: 1.3088881969451904\n",
      "Saved P and Q at step 37\n",
      "Prediction Error: 1.2925076484680176\n",
      "Saved P and Q at step 38\n",
      "Prediction Error: 1.2767934799194336\n",
      "Saved P and Q at step 39\n",
      "Prediction Error: 1.2617146968841553\n",
      "Saved P and Q at step 40\n",
      "Prediction Error: 1.2472422122955322\n",
      "Saved P and Q at step 41\n",
      "Prediction Error: 1.2333483695983887\n",
      "Saved P and Q at step 42\n",
      "Prediction Error: 1.220007061958313\n",
      "Saved P and Q at step 43\n",
      "Prediction Error: 1.20719313621521\n",
      "Saved P and Q at step 44\n",
      "Prediction Error: 1.1948829889297485\n",
      "Saved P and Q at step 45\n",
      "Prediction Error: 1.1830544471740723\n",
      "Saved P and Q at step 46\n",
      "Prediction Error: 1.171685814857483\n",
      "Saved P and Q at step 47\n",
      "Prediction Error: 1.1607571840286255\n",
      "Saved P and Q at step 48\n",
      "Prediction Error: 1.1502488851547241\n",
      "Saved P and Q at step 49\n",
      "Prediction Error: 1.1401429176330566\n",
      "Saved P and Q at step 50\n",
      "Prediction Error: 1.130421757698059\n",
      "Saved P and Q at step 51\n",
      "Prediction Error: 1.1210688352584839\n",
      "Saved P and Q at step 52\n",
      "Prediction Error: 1.1120684146881104\n",
      "Saved P and Q at step 53\n",
      "Prediction Error: 1.1034053564071655\n",
      "Saved P and Q at step 54\n",
      "Prediction Error: 1.0950654745101929\n",
      "Saved P and Q at step 55\n",
      "Prediction Error: 1.087035059928894\n",
      "Saved P and Q at step 56\n",
      "Prediction Error: 1.0793009996414185\n",
      "Saved P and Q at step 57\n",
      "Prediction Error: 1.0718512535095215\n",
      "Saved P and Q at step 58\n",
      "Prediction Error: 1.0646737813949585\n",
      "Saved P and Q at step 59\n",
      "Prediction Error: 1.0577574968338013\n",
      "Saved P and Q at step 60\n",
      "Prediction Error: 1.0510913133621216\n",
      "Saved P and Q at step 61\n",
      "Prediction Error: 1.0446654558181763\n",
      "Saved P and Q at step 62\n",
      "Prediction Error: 1.0384697914123535\n",
      "Saved P and Q at step 63\n",
      "Prediction Error: 1.032495141029358\n",
      "Saved P and Q at step 64\n",
      "Prediction Error: 1.0267325639724731\n",
      "Saved P and Q at step 65\n",
      "Prediction Error: 1.0211735963821411\n",
      "Saved P and Q at step 66\n",
      "Prediction Error: 1.0158098936080933\n",
      "Saved P and Q at step 67\n",
      "Prediction Error: 1.0106340646743774\n",
      "Saved P and Q at step 68\n",
      "Prediction Error: 1.0056383609771729\n",
      "Saved P and Q at step 69\n",
      "Prediction Error: 1.000815749168396\n",
      "Saved P and Q at step 70\n",
      "Prediction Error: 0.9961596727371216\n",
      "Saved P and Q at step 71\n",
      "Prediction Error: 0.9916633367538452\n",
      "Saved P and Q at step 72\n",
      "Prediction Error: 0.9873207211494446\n",
      "Saved P and Q at step 73\n",
      "Prediction Error: 0.9831258058547974\n",
      "Saved P and Q at step 74\n",
      "Prediction Error: 0.9790729880332947\n",
      "Saved P and Q at step 75\n",
      "Prediction Error: 0.9751567244529724\n",
      "Saved P and Q at step 76\n",
      "Prediction Error: 0.9713718891143799\n",
      "Saved P and Q at step 77\n",
      "Prediction Error: 0.9677134156227112\n",
      "Saved P and Q at step 78\n",
      "Prediction Error: 0.9641766548156738\n",
      "Saved P and Q at step 79\n",
      "Prediction Error: 0.9607569575309753\n",
      "Saved P and Q at step 80\n",
      "Prediction Error: 0.9574499130249023\n",
      "Saved P and Q at step 81\n",
      "Prediction Error: 0.9542514085769653\n",
      "Saved P and Q at step 82\n",
      "Prediction Error: 0.9511573910713196\n",
      "Saved P and Q at step 83\n",
      "Prediction Error: 0.9481639266014099\n",
      "Saved P and Q at step 84\n",
      "Prediction Error: 0.9452674388885498\n",
      "Saved P and Q at step 85\n",
      "Prediction Error: 0.942464292049408\n",
      "Saved P and Q at step 86\n",
      "Prediction Error: 0.9397510290145874\n",
      "Saved P and Q at step 87\n",
      "Prediction Error: 0.9371246099472046\n",
      "Saved P and Q at step 88\n",
      "Prediction Error: 0.9345816969871521\n",
      "Saved P and Q at step 89\n",
      "Prediction Error: 0.9321194291114807\n",
      "Saved P and Q at step 90\n",
      "Prediction Error: 0.9297347068786621\n",
      "Saved P and Q at step 91\n",
      "Prediction Error: 0.927424967288971\n",
      "Saved P and Q at step 92\n",
      "Prediction Error: 0.9251874685287476\n",
      "Saved P and Q at step 93\n",
      "Prediction Error: 0.9230197072029114\n",
      "Saved P and Q at step 94\n",
      "Prediction Error: 0.9209192395210266\n",
      "Saved P and Q at step 95\n",
      "Prediction Error: 0.9188836216926575\n",
      "Saved P and Q at step 96\n",
      "Prediction Error: 0.9169106483459473\n",
      "Saved P and Q at step 97\n",
      "Prediction Error: 0.9149981737136841\n",
      "Saved P and Q at step 98\n",
      "Prediction Error: 0.9131439924240112\n",
      "Saved P and Q at step 99\n",
      "Prediction Error: 0.9113461971282959\n",
      "Saved P and Q at step 100\n",
      "Prediction Error: 0.9096028208732605\n",
      "Saved P and Q at step 101\n",
      "Prediction Error: 0.907912015914917\n",
      "Saved P and Q at step 102\n",
      "Prediction Error: 0.9062719941139221\n",
      "Saved P and Q at step 103\n",
      "Prediction Error: 0.9046810269355774\n",
      "Saved P and Q at step 104\n",
      "Prediction Error: 0.9031374454498291\n",
      "Saved P and Q at step 105\n",
      "Prediction Error: 0.9016396999359131\n",
      "Saved P and Q at step 106\n",
      "Prediction Error: 0.9001862406730652\n",
      "Saved P and Q at step 107\n",
      "Prediction Error: 0.8987755179405212\n",
      "Saved P and Q at step 108\n",
      "Prediction Error: 0.8974062204360962\n",
      "Saved P and Q at step 109\n",
      "Prediction Error: 0.8960769772529602\n",
      "Saved P and Q at step 110\n",
      "Prediction Error: 0.8947863578796387\n",
      "Saved P and Q at step 111\n",
      "Prediction Error: 0.8935331702232361\n",
      "Saved P and Q at step 112\n",
      "Prediction Error: 0.8923161625862122\n",
      "Saved P and Q at step 113\n",
      "Prediction Error: 0.8911342620849609\n",
      "Saved P and Q at step 114\n",
      "Prediction Error: 0.8899861574172974\n",
      "Saved P and Q at step 115\n",
      "Prediction Error: 0.888870894908905\n",
      "Saved P and Q at step 116\n",
      "Prediction Error: 0.8877873420715332\n",
      "Saved P and Q at step 117\n",
      "Prediction Error: 0.8867344856262207\n",
      "Saved P and Q at step 118\n",
      "Prediction Error: 0.8857113718986511\n",
      "Saved P and Q at step 119\n",
      "Prediction Error: 0.8847171068191528\n",
      "Saved P and Q at step 120\n",
      "Prediction Error: 0.8837506771087646\n",
      "Saved P and Q at step 121\n",
      "Prediction Error: 0.8828112483024597\n",
      "Saved P and Q at step 122\n",
      "Prediction Error: 0.8818979263305664\n",
      "Saved P and Q at step 123\n",
      "Prediction Error: 0.8810099959373474\n",
      "Saved P and Q at step 124\n",
      "Prediction Error: 0.8801465630531311\n",
      "Saved P and Q at step 125\n",
      "Prediction Error: 0.879306972026825\n",
      "Saved P and Q at step 126\n",
      "Prediction Error: 0.8784903287887573\n",
      "Saved P and Q at step 127\n",
      "Prediction Error: 0.8776960372924805\n",
      "Saved P and Q at step 128\n",
      "Prediction Error: 0.8769233822822571\n",
      "Saved P and Q at step 129\n",
      "Prediction Error: 0.8761717081069946\n",
      "Saved P and Q at step 130\n",
      "Prediction Error: 0.8754403591156006\n",
      "Saved P and Q at step 131\n",
      "Prediction Error: 0.8747286796569824\n",
      "Saved P and Q at step 132\n",
      "Prediction Error: 0.8740361928939819\n",
      "Saved P and Q at step 133\n",
      "Prediction Error: 0.8733621835708618\n",
      "Saved P and Q at step 134\n",
      "Prediction Error: 0.8727061748504639\n",
      "Saved P and Q at step 135\n",
      "Prediction Error: 0.8720675706863403\n",
      "Saved P and Q at step 136\n",
      "Prediction Error: 0.8714458346366882\n",
      "Saved P and Q at step 137\n",
      "Prediction Error: 0.8708406090736389\n",
      "Saved P and Q at step 138\n",
      "Prediction Error: 0.8702512979507446\n",
      "Saved P and Q at step 139\n",
      "Prediction Error: 0.8696774244308472\n",
      "Saved P and Q at step 140\n",
      "Prediction Error: 0.8691184520721436\n",
      "Saved P and Q at step 141\n",
      "Prediction Error: 0.8685741424560547\n",
      "Saved P and Q at step 142\n",
      "Prediction Error: 0.868043839931488\n",
      "Saved P and Q at step 143\n",
      "Prediction Error: 0.8675273060798645\n",
      "Saved P and Q at step 144\n",
      "Prediction Error: 0.8670240640640259\n",
      "Saved P and Q at step 145\n",
      "Prediction Error: 0.8665337562561035\n",
      "Saved P and Q at step 146\n",
      "Prediction Error: 0.8660560250282288\n",
      "Saved P and Q at step 147\n",
      "Prediction Error: 0.8655903935432434\n",
      "Saved P and Q at step 148\n",
      "Prediction Error: 0.8651367425918579\n",
      "Saved P and Q at step 149\n",
      "Prediction Error: 0.8646944761276245\n",
      "Saved P and Q at step 150\n",
      "Prediction Error: 0.8642633557319641\n",
      "Saved P and Q at step 151\n",
      "Prediction Error: 0.8638431429862976\n",
      "Saved P and Q at step 152\n",
      "Prediction Error: 0.8634334206581116\n",
      "Saved P and Q at step 153\n",
      "Prediction Error: 0.8630340099334717\n",
      "Saved P and Q at step 154\n",
      "Prediction Error: 0.8626444339752197\n",
      "Saved P and Q at step 155\n",
      "Prediction Error: 0.8622646331787109\n",
      "Saved P and Q at step 156\n",
      "Prediction Error: 0.8618941903114319\n",
      "Saved P and Q at step 157\n",
      "Prediction Error: 0.8615328669548035\n",
      "Saved P and Q at step 158\n",
      "Prediction Error: 0.8611804246902466\n",
      "Saved P and Q at step 159\n",
      "Prediction Error: 0.8608366847038269\n",
      "Saved P and Q at step 160\n",
      "Prediction Error: 0.8605012893676758\n",
      "Saved P and Q at step 161\n",
      "Prediction Error: 0.8601740002632141\n",
      "Saved P and Q at step 162\n",
      "Prediction Error: 0.8598547577857971\n",
      "Saved P and Q at step 163\n",
      "Prediction Error: 0.8595431447029114\n",
      "Saved P and Q at step 164\n",
      "Prediction Error: 0.8592390418052673\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#cont(1125)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36minit\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Run the matrix factorization\u001b[39;00m\n\u001b[1;32m      5\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m P, Q \u001b[38;5;241m=\u001b[39m \u001b[43mmatrix_factorization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrating_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m predicted_ratings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(P, Q\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m     10\u001b[0m actual_ratings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(rating_matrix\u001b[38;5;241m.\u001b[39mtoarray())\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Convert to PyTorch tensor\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m, in \u001b[0;36mmatrix_factorization\u001b[0;34m(R, K, steps, alpha, beta, save_interval, output_dir, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m     P_j \u001b[38;5;241m=\u001b[39m P[rated_indices, :]\n\u001b[1;32m     18\u001b[0m     R_j \u001b[38;5;241m=\u001b[39m R[rated_indices, j]\n\u001b[0;32m---> 19\u001b[0m     e_j \u001b[38;5;241m=\u001b[39m R_j \u001b[38;5;241m-\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP_j\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     Q[:, j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m (torch\u001b[38;5;241m.\u001b[39mmatmul(P_j\u001b[38;5;241m.\u001b[39mT, e_j) \u001b[38;5;241m-\u001b[39m beta \u001b[38;5;241m*\u001b[39m Q[:, j])\n\u001b[1;32m     22\u001b[0m eR \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(P, Q)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init()\n",
    "#cont(1125)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
