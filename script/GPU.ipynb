{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbfaa8ee-7a47-42fa-9162-f330eb98c672",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T16:10:47.897534Z",
     "iopub.status.busy": "2024-01-03T16:10:47.897356Z",
     "iopub.status.idle": "2024-01-03T16:10:49.918163Z",
     "shell.execute_reply": "2024-01-03T16:10:49.917598Z",
     "shell.execute_reply.started": "2024-01-03T16:10:47.897514Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Data Loaded\n",
      "   user_id  book_id  rating\n",
      "0    10714     7164       3\n",
      "1    48091     2213       3\n",
      "2     9809     5769       4\n",
      "3    25191       86       5\n",
      "4    25441     4884       3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim # To use SGD\n",
    "from scipy.sparse import coo_matrix\n",
    "import os\n",
    "\n",
    "d = '/mnt/workspace/Book-Rec-Sys/input'\n",
    "o = '/mnt/workspace/Book-Rec-Sys/output'\n",
    "\n",
    "def load_data():\n",
    "    ratings = pd.read_csv(f'{d}/train_data.csv')\n",
    "    print(\"Ratings Data Loaded\")\n",
    "    print(ratings.head())\n",
    "    return ratings\n",
    "\n",
    "ratings = load_data()\n",
    "\n",
    "num_users = ratings['user_id'].max()\n",
    "num_books = ratings['book_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc97b93-c5fb-4e00-8ad9-0523393e5f97",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T16:10:49.919154Z",
     "iopub.status.busy": "2024-01-03T16:10:49.918969Z",
     "iopub.status.idle": "2024-01-03T16:10:49.964007Z",
     "shell.execute_reply": "2024-01-03T16:10:49.963390Z",
     "shell.execute_reply.started": "2024-01-03T16:10:49.919135Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to a sparse matrix\n",
    "rows = ratings['user_id'] - 1\n",
    "cols = ratings['book_id'] - 1\n",
    "values = ratings['rating']\n",
    "rating_matrix = coo_matrix((values, (rows, cols)), shape=(num_users, num_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3a854c-f541-4bc7-8ac6-a83a32aed11c",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T16:10:49.965815Z",
     "iopub.status.busy": "2024-01-03T16:10:49.965376Z",
     "iopub.status.idle": "2024-01-03T16:10:49.972987Z",
     "shell.execute_reply": "2024-01-03T16:10:49.972397Z",
     "shell.execute_reply.started": "2024-01-03T16:10:49.965792Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matrix_factorization(R, K, steps=5000, alpha=0.000005, beta=0, save_interval=500, output_dir='output', device='cuda'):\n",
    "    R = torch.FloatTensor(R.toarray()).to(device)\n",
    "    num_users, num_books = R.shape\n",
    "    # Added requires_grad=True to P and Q so that PyTorch tracks operations on them for automatic differentiation.\n",
    "#    P = torch.rand(num_users, K, requires_grad=True, device=device)\n",
    "#    Q = torch.rand(num_books, K, requires_grad=True, device=device).T\n",
    "\n",
    "    P = torch.rand(num_users, K)\n",
    "    P = P.cuda()\n",
    "    P.requires_grad = True\n",
    "\n",
    "    Q = torch.rand(num_books, K).T\n",
    "    Q = Q.cuda()\n",
    "    Q.requires_grad = True\n",
    "    \n",
    "    # Initialized the SGD optimizer with P and Q as the parameters to be updated and alpha as the learning rate.\n",
    "    optimizer = optim.SGD([P, Q], lr=alpha)\n",
    "    \n",
    "    for step in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        eR = torch.matmul(P, Q)\n",
    "        mask = R > 0\n",
    "        loss = torch.sum((mask * (R - eR)) ** 2)\n",
    "        loss += beta / 2 * (torch.sum(P ** 2) + torch.sum(Q ** 2))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('step:', step)\n",
    "        print(\"loss:\", loss.item())\n",
    "\n",
    "\n",
    "        predicted_ratings = torch.matmul(P, Q)\n",
    "        actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "        mask = actual_ratings > 0\n",
    "        # Ensure both tensors are on the same device before subtraction\n",
    "        error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "        print(\"Prediction Error:\", error.item())  # Convert to Python scalar for printing\n",
    "\n",
    "        # Save P and Q every 'save_interval' steps, print loss function calculate the prediction error\n",
    "        if step % save_interval == 0 or step == steps - 1:\n",
    "            torch.save(P, os.path.join(output_dir, f'P_step_{step}_alpha_{alpha}_beta_{beta}.pt'))\n",
    "            torch.save(Q, os.path.join(output_dir, f'Q_step_{step}_alpha_{alpha}_beta_{beta}.pt'))\n",
    "            print(f'Saved P and Q')\n",
    "\n",
    "        if loss.item() < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d65856a3-28a2-4424-96ce-6f8182c8c4ea",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T16:10:49.973984Z",
     "iopub.status.busy": "2024-01-03T16:10:49.973655Z",
     "iopub.status.idle": "2024-01-03T16:10:49.981318Z",
     "shell.execute_reply": "2024-01-03T16:10:49.980777Z",
     "shell.execute_reply.started": "2024-01-03T16:10:49.973965Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matrix_factorization_continue(R, K, end_step, steps=5000, alpha=0.00002, beta=0.01, save_interval=125, output_dir='output', device='cuda'):\n",
    "    R = torch.FloatTensor(R.toarray()).to(device)\n",
    "    num_users, num_books = R.shape\n",
    "    # Attempt to load P and Q from saved files\n",
    "    P_path = os.path.join(output_dir, f'P_step_{end_step}.pt')\n",
    "    Q_path = os.path.join(output_dir, f'Q_step_{end_step}.pt')\n",
    "    P = torch.load(P_path, map_location=device)\n",
    "    Q = torch.load(Q_path, map_location=device)\n",
    "    print(f\"Continuing from step {end_step}...\")\n",
    "\n",
    "\n",
    "    for step in range(end_step+1, steps):\n",
    "        # Matrix factorization steps...\n",
    "        # Existing matrix factorization logic in matrix_factorization\n",
    "        for i in range(num_users):\n",
    "            rated_indices = R[i, :].nonzero().view(-1)\n",
    "            Q_i = Q[:, rated_indices]\n",
    "            R_i = R[i, rated_indices]\n",
    "            e_i = R_i - torch.matmul(P[i, :], Q_i)\n",
    "            P[i, :] += alpha * (torch.matmul(e_i, Q_i.T) - beta * P[i, :])\n",
    "\n",
    "        for j in range(num_books):\n",
    "            rated_indices = R[:, j].nonzero().view(-1)\n",
    "            P_j = P[rated_indices, :]\n",
    "            R_j = R[rated_indices, j]\n",
    "            e_j = R_j - torch.matmul(P_j, Q[:, j])\n",
    "            Q[:, j] += alpha * (torch.matmul(P_j.T, e_j) - beta * Q[:, j])\n",
    "\n",
    "        eR = torch.matmul(P, Q)\n",
    "        e = torch.sum((R[R > 0] - eR[R > 0]) ** 2)\n",
    "        e += beta / 2 * (torch.sum(P ** 2) + torch.sum(Q ** 2))\n",
    "        \n",
    "        \n",
    "        # Save P and Q every 'save_interval' steps\n",
    "        if step % save_interval == 0 or step == steps - 1:\n",
    "            torch.save(P, os.path.join(output_dir, f'P_step_{step}.pt'))\n",
    "            torch.save(Q, os.path.join(output_dir, f'Q_step_{step}.pt'))\n",
    "            print(f'Saved P and Q at step {step}')\n",
    "\n",
    "        if e < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd17e94-3e32-4ae8-b71a-532f56f03e5e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T16:10:49.982262Z",
     "iopub.status.busy": "2024-01-03T16:10:49.981955Z",
     "iopub.status.idle": "2024-01-03T16:10:49.985090Z",
     "shell.execute_reply": "2024-01-03T16:10:49.984555Z",
     "shell.execute_reply.started": "2024-01-03T16:10:49.982243Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init(K=2):\n",
    "    # Run the matrix factorization\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    P, Q = matrix_factorization(rating_matrix, K, device=device, output_dir=o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c785f1-7e14-42f5-8680-ddf0d1623339",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T16:10:49.985980Z",
     "iopub.status.busy": "2024-01-03T16:10:49.985701Z",
     "iopub.status.idle": "2024-01-03T16:10:49.989523Z",
     "shell.execute_reply": "2024-01-03T16:10:49.989042Z",
     "shell.execute_reply.started": "2024-01-03T16:10:49.985962Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cont(end_step):\n",
    "    K = 2  # Example value\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    P, Q = matrix_factorization_continue(rating_matrix, K, end_step, device=device, output_dir=o)\n",
    "\n",
    "    predicted_ratings = torch.matmul(P, Q.T)\n",
    "    actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "    mask = actual_ratings > 0\n",
    "\n",
    "    # Ensure both tensors are on the same device before subtraction\n",
    "    error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "247b02e1-6c02-4441-8fff-c6ecf0167565",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T16:10:49.990499Z",
     "iopub.status.busy": "2024-01-03T16:10:49.990206Z",
     "iopub.status.idle": "2024-01-03T16:10:49.992789Z",
     "shell.execute_reply": "2024-01-03T16:10:49.992264Z",
     "shell.execute_reply.started": "2024-01-03T16:10:49.990480Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Empty cuda memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6282ea-c55b-437d-8a28-796b714a158b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T16:10:49.993528Z",
     "iopub.status.busy": "2024-01-03T16:10:49.993363Z",
     "iopub.status.idle": "2024-01-03T16:14:21.619308Z",
     "shell.execute_reply": "2024-01-03T16:14:21.618396Z",
     "shell.execute_reply.started": "2024-01-03T16:10:49.993511Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "loss: 60949392.0\n",
      "Prediction Error: 3.5272436141967773\n",
      "Saved P and Q\n",
      "step: 1\n",
      "loss: 59484836.0\n",
      "Prediction Error: 3.486626386642456\n",
      "step: 2\n",
      "loss: 58122752.0\n",
      "Prediction Error: 3.4482696056365967\n",
      "step: 3\n",
      "loss: 56850964.0\n",
      "Prediction Error: 3.411933422088623\n",
      "step: 4\n",
      "loss: 55659132.0\n",
      "Prediction Error: 3.377408266067505\n",
      "step: 5\n",
      "loss: 54538416.0\n",
      "Prediction Error: 3.344513177871704\n",
      "step: 6\n",
      "loss: 53481208.0\n",
      "Prediction Error: 3.3130886554718018\n",
      "step: 7\n",
      "loss: 52480928.0\n",
      "Prediction Error: 3.2829952239990234\n",
      "step: 8\n",
      "loss: 51531864.0\n",
      "Prediction Error: 3.2541093826293945\n",
      "step: 9\n",
      "loss: 50629040.0\n",
      "Prediction Error: 3.2263224124908447\n",
      "step: 10\n",
      "loss: 49768080.0\n",
      "Prediction Error: 3.199537515640259\n",
      "step: 11\n",
      "loss: 48945160.0\n",
      "Prediction Error: 3.173668622970581\n",
      "step: 12\n",
      "loss: 48156900.0\n",
      "Prediction Error: 3.148639440536499\n",
      "step: 13\n",
      "loss: 47400312.0\n",
      "Prediction Error: 3.1243808269500732\n",
      "step: 14\n",
      "loss: 46672744.0\n",
      "Prediction Error: 3.10083270072937\n",
      "step: 15\n",
      "loss: 45971856.0\n",
      "Prediction Error: 3.077939510345459\n",
      "step: 16\n",
      "loss: 45295552.0\n",
      "Prediction Error: 3.055652618408203\n",
      "step: 17\n",
      "loss: 44641968.0\n",
      "Prediction Error: 3.0339274406433105\n",
      "step: 18\n",
      "loss: 44009432.0\n",
      "Prediction Error: 3.0127246379852295\n",
      "step: 19\n",
      "loss: 43396456.0\n",
      "Prediction Error: 2.9920084476470947\n",
      "step: 20\n",
      "loss: 42801696.0\n",
      "Prediction Error: 2.9717466831207275\n",
      "step: 21\n",
      "loss: 42223952.0\n",
      "Prediction Error: 2.9519100189208984\n",
      "step: 22\n",
      "loss: 41662140.0\n",
      "Prediction Error: 2.9324727058410645\n",
      "step: 23\n",
      "loss: 41115280.0\n",
      "Prediction Error: 2.9134104251861572\n",
      "step: 24\n",
      "loss: 40582492.0\n",
      "Prediction Error: 2.894702196121216\n",
      "step: 25\n",
      "loss: 40062968.0\n",
      "Prediction Error: 2.8763279914855957\n",
      "Saved P and Q\n",
      "step: 26\n",
      "loss: 39555988.0\n",
      "Prediction Error: 2.8582708835601807\n",
      "step: 27\n",
      "loss: 39060888.0\n",
      "Prediction Error: 2.8405141830444336\n",
      "step: 28\n",
      "loss: 38577068.0\n",
      "Prediction Error: 2.823042869567871\n",
      "step: 29\n",
      "loss: 38103984.0\n",
      "Prediction Error: 2.805844783782959\n",
      "step: 30\n",
      "loss: 37641124.0\n",
      "Prediction Error: 2.7889063358306885\n",
      "step: 31\n",
      "loss: 37188036.0\n",
      "Prediction Error: 2.772217273712158\n",
      "step: 32\n",
      "loss: 36744296.0\n",
      "Prediction Error: 2.755767345428467\n",
      "step: 33\n",
      "loss: 36309512.0\n",
      "Prediction Error: 2.739546775817871\n",
      "step: 34\n",
      "loss: 35883336.0\n",
      "Prediction Error: 2.7235472202301025\n",
      "step: 35\n",
      "loss: 35465420.0\n",
      "Prediction Error: 2.7077600955963135\n",
      "step: 36\n",
      "loss: 35055464.0\n",
      "Prediction Error: 2.692178964614868\n",
      "step: 37\n",
      "loss: 34653184.0\n",
      "Prediction Error: 2.6767964363098145\n",
      "step: 38\n",
      "loss: 34258316.0\n",
      "Prediction Error: 2.6616063117980957\n",
      "step: 39\n",
      "loss: 33870608.0\n",
      "Prediction Error: 2.6466031074523926\n",
      "step: 40\n",
      "loss: 33489832.0\n",
      "Prediction Error: 2.6317808628082275\n",
      "step: 41\n",
      "loss: 33115766.0\n",
      "Prediction Error: 2.6171345710754395\n",
      "step: 42\n",
      "loss: 32748208.0\n",
      "Prediction Error: 2.6026601791381836\n",
      "step: 43\n",
      "loss: 32386968.0\n",
      "Prediction Error: 2.5883524417877197\n",
      "step: 44\n",
      "loss: 32031864.0\n",
      "Prediction Error: 2.5742075443267822\n",
      "step: 45\n",
      "loss: 31682724.0\n",
      "Prediction Error: 2.5602216720581055\n",
      "step: 46\n",
      "loss: 31339388.0\n",
      "Prediction Error: 2.546391010284424\n",
      "step: 47\n",
      "loss: 31001700.0\n",
      "Prediction Error: 2.532711982727051\n",
      "step: 48\n",
      "loss: 30669520.0\n",
      "Prediction Error: 2.519181489944458\n",
      "step: 49\n",
      "loss: 30342704.0\n",
      "Prediction Error: 2.505796194076538\n",
      "step: 50\n",
      "loss: 30021122.0\n",
      "Prediction Error: 2.4925537109375\n",
      "Saved P and Q\n",
      "step: 51\n",
      "loss: 29704648.0\n",
      "Prediction Error: 2.4794507026672363\n",
      "step: 52\n",
      "loss: 29393160.0\n",
      "Prediction Error: 2.466484546661377\n",
      "step: 53\n",
      "loss: 29086548.0\n",
      "Prediction Error: 2.453652858734131\n",
      "step: 54\n",
      "loss: 28784694.0\n",
      "Prediction Error: 2.440953254699707\n",
      "step: 55\n",
      "loss: 28487496.0\n",
      "Prediction Error: 2.4283831119537354\n",
      "step: 56\n",
      "loss: 28194850.0\n",
      "Prediction Error: 2.415940523147583\n",
      "step: 57\n",
      "loss: 27906660.0\n",
      "Prediction Error: 2.403623342514038\n",
      "step: 58\n",
      "loss: 27622830.0\n",
      "Prediction Error: 2.3914291858673096\n",
      "step: 59\n",
      "loss: 27343272.0\n",
      "Prediction Error: 2.379356622695923\n",
      "step: 60\n",
      "loss: 27067892.0\n",
      "Prediction Error: 2.367403268814087\n",
      "step: 61\n",
      "loss: 26796608.0\n",
      "Prediction Error: 2.355567216873169\n",
      "step: 62\n",
      "loss: 26529340.0\n",
      "Prediction Error: 2.3438472747802734\n",
      "step: 63\n",
      "loss: 26266004.0\n",
      "Prediction Error: 2.3322415351867676\n",
      "step: 64\n",
      "loss: 26006526.0\n",
      "Prediction Error: 2.3207478523254395\n",
      "step: 65\n",
      "loss: 25750834.0\n",
      "Prediction Error: 2.3093650341033936\n",
      "step: 66\n",
      "loss: 25498848.0\n",
      "Prediction Error: 2.2980916500091553\n",
      "step: 67\n",
      "loss: 25250504.0\n",
      "Prediction Error: 2.286925792694092\n",
      "step: 68\n",
      "loss: 25005730.0\n",
      "Prediction Error: 2.2758662700653076\n",
      "step: 69\n",
      "loss: 24764462.0\n",
      "Prediction Error: 2.264911651611328\n",
      "step: 70\n",
      "loss: 24526632.0\n",
      "Prediction Error: 2.2540605068206787\n",
      "step: 71\n",
      "loss: 24292182.0\n",
      "Prediction Error: 2.2433114051818848\n",
      "step: 72\n",
      "loss: 24061048.0\n",
      "Prediction Error: 2.232663154602051\n",
      "step: 73\n",
      "loss: 23833168.0\n",
      "Prediction Error: 2.222114324569702\n",
      "step: 74\n",
      "loss: 23608488.0\n",
      "Prediction Error: 2.2116637229919434\n",
      "step: 75\n",
      "loss: 23386950.0\n",
      "Prediction Error: 2.201310396194458\n",
      "Saved P and Q\n",
      "step: 76\n",
      "loss: 23168500.0\n",
      "Prediction Error: 2.1910526752471924\n",
      "step: 77\n",
      "loss: 22953080.0\n",
      "Prediction Error: 2.18088960647583\n",
      "step: 78\n",
      "loss: 22740640.0\n",
      "Prediction Error: 2.1708199977874756\n",
      "step: 79\n",
      "loss: 22531132.0\n",
      "Prediction Error: 2.1608428955078125\n",
      "step: 80\n",
      "loss: 22324498.0\n",
      "Prediction Error: 2.150956869125366\n",
      "step: 81\n",
      "loss: 22120696.0\n",
      "Prediction Error: 2.1411614418029785\n",
      "step: 82\n",
      "loss: 21919676.0\n",
      "Prediction Error: 2.1314547061920166\n",
      "step: 83\n",
      "loss: 21721390.0\n",
      "Prediction Error: 2.1218364238739014\n",
      "step: 84\n",
      "loss: 21525792.0\n",
      "Prediction Error: 2.112305164337158\n",
      "step: 85\n",
      "loss: 21332840.0\n",
      "Prediction Error: 2.1028597354888916\n",
      "step: 86\n",
      "loss: 21142484.0\n",
      "Prediction Error: 2.0934998989105225\n",
      "step: 87\n",
      "loss: 20954688.0\n",
      "Prediction Error: 2.084223747253418\n",
      "step: 88\n",
      "loss: 20769406.0\n",
      "Prediction Error: 2.075031280517578\n",
      "step: 89\n",
      "loss: 20586598.0\n",
      "Prediction Error: 2.06592059135437\n",
      "step: 90\n",
      "loss: 20406224.0\n",
      "Prediction Error: 2.056891679763794\n",
      "step: 91\n",
      "loss: 20228244.0\n",
      "Prediction Error: 2.047942876815796\n",
      "step: 92\n",
      "loss: 20052620.0\n",
      "Prediction Error: 2.039073944091797\n",
      "step: 93\n",
      "loss: 19879312.0\n",
      "Prediction Error: 2.0302836894989014\n",
      "step: 94\n",
      "loss: 19708284.0\n",
      "Prediction Error: 2.021571159362793\n",
      "step: 95\n",
      "loss: 19539500.0\n",
      "Prediction Error: 2.0129356384277344\n",
      "step: 96\n",
      "loss: 19372924.0\n",
      "Prediction Error: 2.0043764114379883\n",
      "step: 97\n",
      "loss: 19208520.0\n",
      "Prediction Error: 1.9958924055099487\n",
      "step: 98\n",
      "loss: 19046256.0\n",
      "Prediction Error: 1.987483024597168\n",
      "step: 99\n",
      "loss: 18886096.0\n",
      "Prediction Error: 1.9791473150253296\n",
      "step: 100\n",
      "loss: 18728008.0\n",
      "Prediction Error: 1.9708845615386963\n",
      "Saved P and Q\n",
      "step: 101\n",
      "loss: 18571960.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#cont(1125)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36minit\u001b[0;34m(K)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit\u001b[39m(K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Run the matrix factorization\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     P, Q \u001b[38;5;241m=\u001b[39m \u001b[43mmatrix_factorization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrating_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36mmatrix_factorization\u001b[0;34m(R, K, steps, alpha, beta, save_interval, output_dir, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     31\u001b[0m predicted_ratings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(P, Q)\n\u001b[0;32m---> 32\u001b[0m actual_ratings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[43mrating_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Convert to PyTorch tensor\u001b[39;00m\n\u001b[1;32m     33\u001b[0m mask \u001b[38;5;241m=\u001b[39m actual_ratings \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Ensure both tensors are on the same device before subtraction\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scipy/sparse/_coo.py:334\u001b[0m, in \u001b[0;36m_coo_base.toarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    333\u001b[0m M,N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 334\u001b[0m \u001b[43mcoo_todense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnnz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m            \u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfortran\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m B\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init(2)\n",
    "#cont(1125)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
