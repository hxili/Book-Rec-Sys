{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbfaa8ee-7a47-42fa-9162-f330eb98c672",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:16.503802Z",
     "iopub.status.busy": "2024-01-03T09:03:16.503621Z",
     "iopub.status.idle": "2024-01-03T09:03:18.641398Z",
     "shell.execute_reply": "2024-01-03T09:03:18.640810Z",
     "shell.execute_reply.started": "2024-01-03T09:03:16.503782Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Data Loaded\n",
      "   user_id  book_id  rating\n",
      "0    10714     7164       3\n",
      "1    48091     2213       3\n",
      "2     9809     5769       4\n",
      "3    25191       86       5\n",
      "4    25441     4884       3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.sparse import coo_matrix\n",
    "import os\n",
    "\n",
    "d = '/mnt/workspace/Book-Rec-Sys/input'\n",
    "o = '/mnt/workspace/Book-Rec-Sys/output'\n",
    "\n",
    "def load_data():\n",
    "    ratings = pd.read_csv(f'{d}/train_data.csv')\n",
    "    print(\"Ratings Data Loaded\")\n",
    "    print(ratings.head())\n",
    "    return ratings\n",
    "\n",
    "ratings = load_data()\n",
    "\n",
    "num_users = ratings['user_id'].max()\n",
    "num_books = ratings['book_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc97b93-c5fb-4e00-8ad9-0523393e5f97",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:18.642565Z",
     "iopub.status.busy": "2024-01-03T09:03:18.642209Z",
     "iopub.status.idle": "2024-01-03T09:03:18.692656Z",
     "shell.execute_reply": "2024-01-03T09:03:18.692089Z",
     "shell.execute_reply.started": "2024-01-03T09:03:18.642544Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to a sparse matrix\n",
    "rows = ratings['user_id'] - 1\n",
    "cols = ratings['book_id'] - 1\n",
    "values = ratings['rating']\n",
    "rating_matrix = coo_matrix((values, (rows, cols)), shape=(num_users, num_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3a854c-f541-4bc7-8ac6-a83a32aed11c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:18.694597Z",
     "iopub.status.busy": "2024-01-03T09:03:18.694298Z",
     "iopub.status.idle": "2024-01-03T09:03:18.702705Z",
     "shell.execute_reply": "2024-01-03T09:03:18.702125Z",
     "shell.execute_reply.started": "2024-01-03T09:03:18.694576Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matrix_factorization(R, K, steps=5000, alpha=0.00005, beta=0.01, save_interval=1, output_dir='output', device='cuda'):\n",
    "    R = torch.FloatTensor(R.toarray()).to(device)\n",
    "    num_users, num_books = R.shape\n",
    "    P = torch.rand(num_users, K, device=device)\n",
    "    Q = torch.rand(num_books, K, device=device).T\n",
    "\n",
    "    for step in range(steps):\n",
    "        for i in range(num_users):\n",
    "            rated_indices = R[i, :].nonzero().view(-1)\n",
    "            Q_i = Q[:, rated_indices]\n",
    "            R_i = R[i, rated_indices]\n",
    "            e_i = R_i - torch.matmul(P[i, :], Q_i)\n",
    "            P[i, :] += alpha * (torch.matmul(e_i, Q_i.T) - beta * P[i, :])\n",
    "\n",
    "        for j in range(num_books):\n",
    "            rated_indices = R[:, j].nonzero().view(-1)\n",
    "            P_j = P[rated_indices, :]\n",
    "            R_j = R[rated_indices, j]\n",
    "            e_j = R_j - torch.matmul(P_j, Q[:, j])\n",
    "            Q[:, j] += alpha * (torch.matmul(P_j.T, e_j) - beta * Q[:, j])\n",
    "\n",
    "        eR = torch.matmul(P, Q)\n",
    "        e = torch.sum((R[R > 0] - eR[R > 0]) ** 2)\n",
    "        e += beta / 2 * (torch.sum(P ** 2) + torch.sum(Q ** 2))\n",
    "        \n",
    "        # Save P and Q every 'save_interval' steps\n",
    "        if step % save_interval == 0 or step == steps - 1:\n",
    "#            torch.save(P, os.path.join(output_dir, f'P_step_{step}_alpha_{alpha}_beta_{beta}.pt'))\n",
    "#            torch.save(Q, os.path.join(output_dir, f'Q_step_{step}_alpha_{alpha}_beta_{beta}.pt'))\n",
    "            print(f'Saved P and Q at step {step}')\n",
    "            \n",
    "            predicted_ratings = torch.matmul(P, Q)\n",
    "            actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "            mask = actual_ratings > 0\n",
    "            # Ensure both tensors are on the same device before subtraction\n",
    "            error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "            print(\"Prediction Error:\", error.item())  # Convert to Python scalar for printing\n",
    "\n",
    "        if e < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d65856a3-28a2-4424-96ce-6f8182c8c4ea",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:18.703807Z",
     "iopub.status.busy": "2024-01-03T09:03:18.703520Z",
     "iopub.status.idle": "2024-01-03T09:03:18.712054Z",
     "shell.execute_reply": "2024-01-03T09:03:18.711496Z",
     "shell.execute_reply.started": "2024-01-03T09:03:18.703779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matrix_factorization_continue(R, K, end_step, steps=5000, alpha=0.0000001, beta=0.01, save_interval=125, output_dir='output', device='cuda'):\n",
    "    R = torch.FloatTensor(R.toarray()).to(device)\n",
    "    num_users, num_books = R.shape\n",
    "    # Attempt to load P and Q from saved files\n",
    "    P_path = os.path.join(output_dir, f'P_step_{end_step}.pt')\n",
    "    Q_path = os.path.join(output_dir, f'Q_step_{end_step}.pt')\n",
    "    P = torch.load(P_path, map_location=device)\n",
    "    Q = torch.load(Q_path, map_location=device)\n",
    "    print(f\"Continuing from step {end_step}...\")\n",
    "\n",
    "\n",
    "    for step in range(end_step+1, steps):\n",
    "        # Matrix factorization steps...\n",
    "        # Existing matrix factorization logic in matrix_factorization\n",
    "        for i in range(num_users):\n",
    "            rated_indices = R[i, :].nonzero().view(-1)\n",
    "            Q_i = Q[:, rated_indices]\n",
    "            R_i = R[i, rated_indices]\n",
    "            e_i = R_i - torch.matmul(P[i, :], Q_i)\n",
    "            P[i, :] += alpha * (torch.matmul(e_i, Q_i.T) - beta * P[i, :])\n",
    "\n",
    "        for j in range(num_books):\n",
    "            rated_indices = R[:, j].nonzero().view(-1)\n",
    "            P_j = P[rated_indices, :]\n",
    "            R_j = R[rated_indices, j]\n",
    "            e_j = R_j - torch.matmul(P_j, Q[:, j])\n",
    "            Q[:, j] += alpha * (torch.matmul(P_j.T, e_j) - beta * Q[:, j])\n",
    "\n",
    "        eR = torch.matmul(P, Q)\n",
    "        e = torch.sum((R[R > 0] - eR[R > 0]) ** 2)\n",
    "        e += beta / 2 * (torch.sum(P ** 2) + torch.sum(Q ** 2))\n",
    "        \n",
    "        \n",
    "        # Save P and Q every 'save_interval' steps\n",
    "        if step % save_interval == 0 or step == steps - 1:\n",
    "            torch.save(P, os.path.join(output_dir, f'P_step_{step}.pt'))\n",
    "            torch.save(Q, os.path.join(output_dir, f'Q_step_{step}.pt'))\n",
    "            print(f'Saved P and Q at step {step}')\n",
    "\n",
    "        if e < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd17e94-3e32-4ae8-b71a-532f56f03e5e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:18.713108Z",
     "iopub.status.busy": "2024-01-03T09:03:18.712843Z",
     "iopub.status.idle": "2024-01-03T09:03:18.716988Z",
     "shell.execute_reply": "2024-01-03T09:03:18.716491Z",
     "shell.execute_reply.started": "2024-01-03T09:03:18.713089Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init():\n",
    "    K = 3\n",
    "\n",
    "    # Run the matrix factorization\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    P, Q = matrix_factorization(rating_matrix, K, device=device, output_dir=o)\n",
    "\n",
    "\n",
    "    predicted_ratings = torch.matmul(P, Q.T)\n",
    "    actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "    mask = actual_ratings > 0\n",
    "\n",
    "    # Ensure both tensors are on the same device before subtraction\n",
    "    error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "\n",
    "    print(\"Prediction Error:\", error.item())  # Convert to Python scalar for printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c785f1-7e14-42f5-8680-ddf0d1623339",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:18.717909Z",
     "iopub.status.busy": "2024-01-03T09:03:18.717711Z",
     "iopub.status.idle": "2024-01-03T09:03:18.721689Z",
     "shell.execute_reply": "2024-01-03T09:03:18.721129Z",
     "shell.execute_reply.started": "2024-01-03T09:03:18.717890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cont(end_step):\n",
    "    K = 2  # Example value\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    P, Q = matrix_factorization_continue(rating_matrix, K, end_step, device=device, output_dir=o)\n",
    "\n",
    "    predicted_ratings = torch.matmul(P, Q.T)\n",
    "    actual_ratings = torch.FloatTensor(rating_matrix.toarray()).to(device)  # Convert to PyTorch tensor\n",
    "    mask = actual_ratings > 0\n",
    "\n",
    "    # Ensure both tensors are on the same device before subtraction\n",
    "    error = torch.sqrt(torch.mean((actual_ratings[mask] - predicted_ratings[mask]) ** 2))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "247b02e1-6c02-4441-8fff-c6ecf0167565",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:18.722535Z",
     "iopub.status.busy": "2024-01-03T09:03:18.722356Z",
     "iopub.status.idle": "2024-01-03T09:03:18.725133Z",
     "shell.execute_reply": "2024-01-03T09:03:18.724586Z",
     "shell.execute_reply.started": "2024-01-03T09:03:18.722515Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Empty cuda memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6282ea-c55b-437d-8a28-796b714a158b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-03T09:03:30.406177Z",
     "iopub.status.busy": "2024-01-03T09:03:30.405801Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved P and Q at step 0\n",
      "Prediction Error: 3.06084942817688\n",
      "Saved P and Q at step 1\n",
      "Prediction Error: 2.8878180980682373\n",
      "Saved P and Q at step 2\n",
      "Prediction Error: 2.756591558456421\n",
      "Saved P and Q at step 3\n",
      "Prediction Error: 2.6476857662200928\n",
      "Saved P and Q at step 4\n",
      "Prediction Error: 2.5528712272644043\n",
      "Saved P and Q at step 5\n",
      "Prediction Error: 2.468003749847412\n",
      "Saved P and Q at step 6\n",
      "Prediction Error: 2.3906948566436768\n",
      "Saved P and Q at step 7\n",
      "Prediction Error: 2.3194313049316406\n",
      "Saved P and Q at step 8\n",
      "Prediction Error: 2.2531867027282715\n",
      "Saved P and Q at step 9\n",
      "Prediction Error: 2.1912310123443604\n",
      "Saved P and Q at step 10\n",
      "Prediction Error: 2.133023977279663\n",
      "Saved P and Q at step 11\n",
      "Prediction Error: 2.0781524181365967\n",
      "Saved P and Q at step 12\n",
      "Prediction Error: 2.026289224624634\n",
      "Saved P and Q at step 13\n",
      "Prediction Error: 1.9771701097488403\n",
      "Saved P and Q at step 14\n",
      "Prediction Error: 1.9305744171142578\n",
      "Saved P and Q at step 15\n",
      "Prediction Error: 1.8863152265548706\n",
      "Saved P and Q at step 16\n",
      "Prediction Error: 1.844230055809021\n",
      "Saved P and Q at step 17\n",
      "Prediction Error: 1.8041765689849854\n",
      "Saved P and Q at step 18\n",
      "Prediction Error: 1.7660274505615234\n",
      "Saved P and Q at step 19\n",
      "Prediction Error: 1.729668378829956\n",
      "Saved P and Q at step 20\n",
      "Prediction Error: 1.6949952840805054\n",
      "Saved P and Q at step 21\n",
      "Prediction Error: 1.6619127988815308\n",
      "Saved P and Q at step 22\n",
      "Prediction Error: 1.6303330659866333\n",
      "Saved P and Q at step 23\n",
      "Prediction Error: 1.6001750230789185\n",
      "Saved P and Q at step 24\n",
      "Prediction Error: 1.5713632106781006\n",
      "Saved P and Q at step 25\n",
      "Prediction Error: 1.5438270568847656\n",
      "Saved P and Q at step 26\n",
      "Prediction Error: 1.517500877380371\n",
      "Saved P and Q at step 27\n",
      "Prediction Error: 1.4923232793807983\n",
      "Saved P and Q at step 28\n",
      "Prediction Error: 1.4682360887527466\n",
      "Saved P and Q at step 29\n",
      "Prediction Error: 1.4451849460601807\n",
      "Saved P and Q at step 30\n",
      "Prediction Error: 1.423119068145752\n",
      "Saved P and Q at step 31\n",
      "Prediction Error: 1.4019896984100342\n",
      "Saved P and Q at step 32\n",
      "Prediction Error: 1.3817517757415771\n",
      "Saved P and Q at step 33\n",
      "Prediction Error: 1.3623621463775635\n",
      "Saved P and Q at step 34\n",
      "Prediction Error: 1.3437801599502563\n",
      "Saved P and Q at step 35\n",
      "Prediction Error: 1.3259676694869995\n",
      "Saved P and Q at step 36\n",
      "Prediction Error: 1.3088881969451904\n",
      "Saved P and Q at step 37\n",
      "Prediction Error: 1.2925076484680176\n",
      "Saved P and Q at step 38\n",
      "Prediction Error: 1.2767934799194336\n",
      "Saved P and Q at step 39\n",
      "Prediction Error: 1.2617146968841553\n",
      "Saved P and Q at step 40\n",
      "Prediction Error: 1.2472422122955322\n",
      "Saved P and Q at step 41\n",
      "Prediction Error: 1.2333483695983887\n",
      "Saved P and Q at step 42\n",
      "Prediction Error: 1.220007061958313\n",
      "Saved P and Q at step 43\n",
      "Prediction Error: 1.20719313621521\n",
      "Saved P and Q at step 44\n",
      "Prediction Error: 1.1948829889297485\n",
      "Saved P and Q at step 45\n",
      "Prediction Error: 1.1830544471740723\n",
      "Saved P and Q at step 46\n",
      "Prediction Error: 1.171685814857483\n",
      "Saved P and Q at step 47\n",
      "Prediction Error: 1.1607571840286255\n",
      "Saved P and Q at step 48\n",
      "Prediction Error: 1.1502488851547241\n",
      "Saved P and Q at step 49\n",
      "Prediction Error: 1.1401429176330566\n",
      "Saved P and Q at step 50\n",
      "Prediction Error: 1.130421757698059\n",
      "Saved P and Q at step 51\n",
      "Prediction Error: 1.1210688352584839\n",
      "Saved P and Q at step 52\n",
      "Prediction Error: 1.1120684146881104\n",
      "Saved P and Q at step 53\n",
      "Prediction Error: 1.1034053564071655\n",
      "Saved P and Q at step 54\n",
      "Prediction Error: 1.0950654745101929\n",
      "Saved P and Q at step 55\n",
      "Prediction Error: 1.087035059928894\n",
      "Saved P and Q at step 56\n",
      "Prediction Error: 1.0793009996414185\n",
      "Saved P and Q at step 57\n",
      "Prediction Error: 1.0718512535095215\n",
      "Saved P and Q at step 58\n",
      "Prediction Error: 1.0646737813949585\n",
      "Saved P and Q at step 59\n",
      "Prediction Error: 1.0577574968338013\n",
      "Saved P and Q at step 60\n",
      "Prediction Error: 1.0510913133621216\n",
      "Saved P and Q at step 61\n",
      "Prediction Error: 1.0446654558181763\n",
      "Saved P and Q at step 62\n",
      "Prediction Error: 1.0384697914123535\n",
      "Saved P and Q at step 63\n",
      "Prediction Error: 1.032495141029358\n",
      "Saved P and Q at step 64\n",
      "Prediction Error: 1.0267325639724731\n",
      "Saved P and Q at step 65\n",
      "Prediction Error: 1.0211735963821411\n",
      "Saved P and Q at step 66\n",
      "Prediction Error: 1.0158098936080933\n",
      "Saved P and Q at step 67\n",
      "Prediction Error: 1.0106340646743774\n",
      "Saved P and Q at step 68\n",
      "Prediction Error: 1.0056383609771729\n",
      "Saved P and Q at step 69\n",
      "Prediction Error: 1.000815749168396\n",
      "Saved P and Q at step 70\n",
      "Prediction Error: 0.9961596727371216\n",
      "Saved P and Q at step 71\n",
      "Prediction Error: 0.9916633367538452\n",
      "Saved P and Q at step 72\n",
      "Prediction Error: 0.9873207211494446\n",
      "Saved P and Q at step 73\n",
      "Prediction Error: 0.9831258058547974\n",
      "Saved P and Q at step 74\n",
      "Prediction Error: 0.9790729880332947\n",
      "Saved P and Q at step 75\n",
      "Prediction Error: 0.9751567244529724\n",
      "Saved P and Q at step 76\n",
      "Prediction Error: 0.9713718891143799\n",
      "Saved P and Q at step 77\n",
      "Prediction Error: 0.9677134156227112\n",
      "Saved P and Q at step 78\n",
      "Prediction Error: 0.9641766548156738\n"
     ]
    }
   ],
   "source": [
    "init()\n",
    "#cont(1125)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
